{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fca273a-e0fc-44d7-8f3b-54d71e9390a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded all samples - X shape: (35887, 2304)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load ALL samples\n",
    "df = pd.read_csv('C:/Users/asus/Downloads/archive/fer2013.csv')\n",
    "X = np.array([np.fromstring(p, sep=' ') for p in df['pixels']]).reshape(-1, 48*48) / 255.0\n",
    "y = to_categorical(df['emotion'])\n",
    "print(\"Loaded all samples - X shape:\", X.shape) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b9c921c-ad2a-4f11-9e99-c77884d4966c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ready!\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(7, activation='softmax', input_shape=(48*48,))\n",
    "])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "print(\"Model ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae3be57b-5743-475d-8d7f-4a686db5c978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2991/2991 [==============================] - 6s 2ms/step - loss: 1.8525\n",
      "Epoch 2/50\n",
      "2991/2991 [==============================] - 4s 1ms/step - loss: 1.7992\n",
      "Epoch 3/50\n",
      "2991/2991 [==============================] - 4s 1ms/step - loss: 1.7748\n",
      "Epoch 4/50\n",
      "2991/2991 [==============================] - 4s 1ms/step - loss: 1.7771\n",
      "Epoch 5/50\n",
      "2991/2991 [==============================] - 3s 1ms/step - loss: 1.7509\n",
      "Epoch 6/50\n",
      "2991/2991 [==============================] - 3s 1ms/step - loss: 1.7578\n",
      "Epoch 7/50\n",
      "2991/2991 [==============================] - 3s 1ms/step - loss: 1.7376\n",
      "Epoch 8/50\n",
      "2991/2991 [==============================] - 3s 1ms/step - loss: 1.7387\n",
      "Epoch 9/50\n",
      "2991/2991 [==============================] - 3s 1ms/step - loss: 1.7265\n",
      "Epoch 10/50\n",
      "2991/2991 [==============================] - 3s 877us/step - loss: 1.7300\n",
      "Epoch 11/50\n",
      "2991/2991 [==============================] - 3s 877us/step - loss: 1.7333\n",
      "Epoch 12/50\n",
      "2991/2991 [==============================] - 3s 880us/step - loss: 1.7231\n",
      "Epoch 13/50\n",
      "2991/2991 [==============================] - 3s 872us/step - loss: 1.7164\n",
      "Epoch 14/50\n",
      "2991/2991 [==============================] - 3s 929us/step - loss: 1.7080\n",
      "Epoch 15/50\n",
      "2991/2991 [==============================] - 3s 877us/step - loss: 1.7165\n",
      "Epoch 16/50\n",
      "2991/2991 [==============================] - 3s 889us/step - loss: 1.7074\n",
      "Epoch 17/50\n",
      "2991/2991 [==============================] - 3s 884us/step - loss: 1.7069\n",
      "Epoch 18/50\n",
      "2991/2991 [==============================] - 3s 876us/step - loss: 1.7022\n",
      "Epoch 19/50\n",
      "2991/2991 [==============================] - 3s 968us/step - loss: 1.7009\n",
      "Epoch 20/50\n",
      "2991/2991 [==============================] - 3s 1ms/step - loss: 1.6907\n",
      "Epoch 21/50\n",
      "2991/2991 [==============================] - 3s 1ms/step - loss: 1.6906\n",
      "Epoch 22/50\n",
      "2991/2991 [==============================] - 3s 1ms/step - loss: 1.6992\n",
      "Epoch 23/50\n",
      "2991/2991 [==============================] - 3s 1ms/step - loss: 1.6909\n",
      "Epoch 24/50\n",
      "2991/2991 [==============================] - 3s 1ms/step - loss: 1.6922\n",
      "Epoch 25/50\n",
      "2991/2991 [==============================] - 3s 966us/step - loss: 1.6806\n",
      "Epoch 26/50\n",
      "2991/2991 [==============================] - 3s 976us/step - loss: 1.6828\n",
      "Epoch 27/50\n",
      "2991/2991 [==============================] - 3s 1ms/step - loss: 1.6834\n",
      "Epoch 28/50\n",
      "2991/2991 [==============================] - 3s 1ms/step - loss: 1.6767\n",
      "Epoch 29/50\n",
      "2991/2991 [==============================] - 3s 1ms/step - loss: 1.6911\n",
      "Epoch 30/50\n",
      "2991/2991 [==============================] - 3s 1ms/step - loss: 1.6878\n",
      "Epoch 31/50\n",
      "2991/2991 [==============================] - 3s 1ms/step - loss: 1.6701\n",
      "Epoch 32/50\n",
      "2991/2991 [==============================] - 3s 920us/step - loss: 1.6690\n",
      "Epoch 33/50\n",
      "2991/2991 [==============================] - 3s 919us/step - loss: 1.6701\n",
      "Epoch 34/50\n",
      "2991/2991 [==============================] - 3s 944us/step - loss: 1.6682\n",
      "Epoch 35/50\n",
      "2991/2991 [==============================] - 3s 997us/step - loss: 1.6781\n",
      "Epoch 36/50\n",
      "2991/2991 [==============================] - 3s 1ms/step - loss: 1.6687\n",
      "Epoch 37/50\n",
      "2991/2991 [==============================] - 3s 984us/step - loss: 1.6636\n",
      "Epoch 38/50\n",
      "2991/2991 [==============================] - 3s 1ms/step - loss: 1.6766\n",
      "Epoch 39/50\n",
      "2991/2991 [==============================] - 3s 982us/step - loss: 1.6736\n",
      "Epoch 40/50\n",
      "2991/2991 [==============================] - 3s 992us/step - loss: 1.6730\n",
      "Epoch 41/50\n",
      "2991/2991 [==============================] - 3s 989us/step - loss: 1.6641\n",
      "Epoch 42/50\n",
      "2991/2991 [==============================] - 3s 1ms/step - loss: 1.6536\n",
      "Epoch 43/50\n",
      "2991/2991 [==============================] - 3s 1ms/step - loss: 1.6645\n",
      "Epoch 44/50\n",
      "2991/2991 [==============================] - 3s 1000us/step - loss: 1.6659\n",
      "Epoch 45/50\n",
      "2991/2991 [==============================] - 3s 998us/step - loss: 1.6564\n",
      "Epoch 46/50\n",
      "2991/2991 [==============================] - 3s 1ms/step - loss: 1.6620\n",
      "Epoch 47/50\n",
      "2991/2991 [==============================] - 3s 993us/step - loss: 1.6521\n",
      "Epoch 48/50\n",
      "2991/2991 [==============================] - 3s 969us/step - loss: 1.6572\n",
      "Epoch 49/50\n",
      "2991/2991 [==============================] - 3s 979us/step - loss: 1.6535\n",
      "Epoch 50/50\n",
      "2991/2991 [==============================] - 3s 990us/step - loss: 1.6553\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, y, epochs=50, batch_size=12)\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afaedb43-b268-484d-92fd-a0dce76608f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'emotion_model.h5'\n"
     ]
    }
   ],
   "source": [
    "model.save('emotion_model.h5')\n",
    "print(\"Model saved as 'emotion_model.h5'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b29f8c-2570-4b52-9b5f-4dd11633b2d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load model and fix metrics warning\n",
    "model = load_model('emotion_model.h5')\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')  # Fixes warning\n",
    "\n",
    "emotions = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        face = cv2.resize(gray[y:y+h,x:x+w], (48,48))\n",
    "        face = face.reshape(1, 48*48) / 255.0  # FLATTEN to (1,2304) \n",
    "        \n",
    "        pred = model.predict(face, verbose=0)[0]\n",
    "        emotion = emotions[np.argmax(pred)]\n",
    "        \n",
    "        cv2.rectangle(frame, (x,y), (x+w,y+h), (255,0,0), 2)\n",
    "        cv2.putText(frame, f\"{emotion}\", (x,y-10), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "    \n",
    "    cv2.imshow('Emotion Detection', frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
